{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KDM_ICP4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqjcwzS24Jr_"
      },
      "source": [
        "Setting up PySpark in Colab\r\n",
        "\r\n",
        "Spark is written in the Scala programming language and requires the Java Virtual Machine (JVM) to run. Therefore, our first task is to download Java"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iGswToj4LIS",
        "outputId": "ef5512d3-b328-49d0-8af2-d19724219194"
      },
      "source": [
        "!sudo apt-get update\r\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzRtNPkq5VIR"
      },
      "source": [
        "Next, we will install Apache Spark 3.0.1 with Hadoop 2.7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBYZfbpk34H3"
      },
      "source": [
        "!wget -q https://www-us.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L21HeCi5bde"
      },
      "source": [
        "Now, we just need to unzip that folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-D2QoWK5cEg"
      },
      "source": [
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grIssZqC8aYj"
      },
      "source": [
        "There is one last thing that we need to install and that is the findspark library. It will locate Spark on the system and import it as a regular library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wke-MaxX57M9"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AJ1RV578hE9"
      },
      "source": [
        "Now that we have installed all the necessary dependencies in Colab, it is time to set the environment path. This will enable us to run Pyspark in the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvMEW0ol59ts"
      },
      "source": [
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weGRBVLK8nKb"
      },
      "source": [
        "We need to locate Spark in the system. For that, we import findspark and use the findspark.init() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSleoMKz6Ecg"
      },
      "source": [
        "import findspark\r\n",
        "findspark.init()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6gW5avs8yWa"
      },
      "source": [
        "If you want to know the location where Spark is installed, use findspark.find()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a3EHL6x76KcK",
        "outputId": "377152c9-f945-4730-87dd-89b3062639ea"
      },
      "source": [
        "findspark.find()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.0.1-bin-hadoop2.7'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI0EI6Ox87wT"
      },
      "source": [
        "Now, we can import SparkSession from pyspark.sql and create a SparkSession, which is the entry point to Spark.\r\n",
        "\r\n",
        "You can give a name to the session using appName() and add some configurations with config() if you wish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcGOvWMJ6PUo"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "\r\n",
        "spark = SparkSession.builder\\\r\n",
        "        .master(\"local\")\\\r\n",
        "        .appName(\"Colab\")\\\r\n",
        "        .config('spark.ui.port', '4050')\\\r\n",
        "        .getOrCreate()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djWQ29kL9Ogy"
      },
      "source": [
        "Finally, print the SparkSession variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "GvcENqE16XEj",
        "outputId": "5428cbe1-a1de-43e6-9119-c68da7628e5d"
      },
      "source": [
        "spark"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://74318d2709db:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f7a7db27780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4btlV8p6b3Q",
        "outputId": "20436a7e-ae61-441a-ecd9-667c6473bf49"
      },
      "source": [
        "#we need to load the dataset. We will use the read.csv module. \r\n",
        "#The inferSchema parameter provided will enable Spark to automatically determine the data type for each column but it has to go over the data once.\r\n",
        "# If you donâ€™t want that to happen, then you can instead provide the schema explicitly in the schema parameter.\r\n",
        "\r\n",
        "df = spark.read.csv(\"/content/data.csv\", header=True, inferSchema= True)\r\n",
        "df.printSchema()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0U-Tk7V7NC5",
        "outputId": "0b09b160-3525-483a-b70d-9863fa3a0179"
      },
      "source": [
        "df.show(5, truncate=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+-------------------------+--------------+------------+-----+\n",
            "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|MultipleLines   |InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|Contract      |PaperlessBilling|PaymentMethod            |MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+-------------------------+--------------+------------+-----+\n",
            "|7590-VHVEG|Female|0            |Yes    |No        |1     |No          |No phone service|DSL            |No            |Yes         |No              |No         |No         |No             |Month-to-month|Yes             |Electronic check         |29.85         |29.85       |No   |\n",
            "|5575-GNVDE|Male  |0            |No     |No        |34    |Yes         |No              |DSL            |Yes           |No          |Yes             |No         |No         |No             |One year      |No              |Mailed check             |56.95         |1889.5      |No   |\n",
            "|3668-QPYBK|Male  |0            |No     |No        |2     |Yes         |No              |DSL            |Yes           |Yes         |No              |No         |No         |No             |Month-to-month|Yes             |Mailed check             |53.85         |108.15      |Yes  |\n",
            "|7795-CFOCW|Male  |0            |No     |No        |45    |No          |No phone service|DSL            |Yes           |No          |Yes             |Yes        |No         |No             |One year      |No              |Bank transfer (automatic)|42.3          |1840.75     |No   |\n",
            "|9237-HQITU|Female|0            |No     |No        |2     |Yes         |No              |Fiber optic    |No            |No          |No              |No         |No         |No             |Month-to-month|Yes             |Electronic check         |70.7          |151.65      |Yes  |\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+-------------------------+--------------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZkvWbw97S7Y",
        "outputId": "2884f919-a8bb-49fb-fb38-78c1fea90628"
      },
      "source": [
        "#If you didn't set inderShema to True, here is what is happening to the type. There are all in string.\r\n",
        "df_string = spark.read.csv(\"/content/data.csv\", header=True, inferSchema=  False)\r\n",
        "df_string.printSchema()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: string (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: string (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: string (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mgfvQEo74_Y",
        "outputId": "823d5004-69b3-4e49-be91-13112c121b55"
      },
      "source": [
        "#You can select and show the rows with select and the names of the features. Below, gender and churn are selected.\r\n",
        "df.select('gender','churn').show(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|gender|churn|\n",
            "+------+-----+\n",
            "|Female|   No|\n",
            "|  Male|   No|\n",
            "|  Male|  Yes|\n",
            "|  Male|   No|\n",
            "|Female|  Yes|\n",
            "+------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-aXM9_x8BIU",
        "outputId": "600cff24-2476-4e9b-9c70-68e15b791e8e"
      },
      "source": [
        "#To get a summary statistics, of the data, you can use describe(). It will compute the :count, mean, standarddeviation, min, max\r\n",
        "df.describe().show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+------------------+-------+----------+------------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
            "|summary|customerID|gender|     SeniorCitizen|Partner|Dependents|            tenure|PhoneService|MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|    MonthlyCharges|      TotalCharges|Churn|\n",
            "+-------+----------+------+------------------+-------+----------+------------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
            "|  count|      7043|  7043|              7043|   7043|      7043|              7043|        7043|         7043|           7043|          7043|        7043|            7043|       7043|       7043|           7043|          7043|            7043|                7043|              7043|              7043| 7043|\n",
            "|   mean|      null|  null|0.1621468124378816|   null|      null| 32.37114865824223|        null|         null|           null|          null|        null|            null|       null|       null|           null|          null|            null|                null| 64.76169246059922|2283.3004408418697| null|\n",
            "| stddev|      null|  null|0.3686116056100135|   null|      null|24.559481023094442|        null|         null|           null|          null|        null|            null|       null|       null|           null|          null|            null|                null|30.090047097678482| 2266.771361883145| null|\n",
            "|    min|0002-ORFBO|Female|                 0|     No|        No|                 0|          No|           No|            DSL|            No|          No|              No|         No|         No|             No|Month-to-month|              No|Bank transfer (au...|             18.25|                  |   No|\n",
            "|    max|9995-HOTOH|  Male|                 1|    Yes|       Yes|                72|         Yes|          Yes|             No|           Yes|         Yes|             Yes|        Yes|        Yes|            Yes|      Two year|             Yes|        Mailed check|            118.75|             999.9|  Yes|\n",
            "+-------+----------+------+------------------+-------+----------+------------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccQW1Roy97p7",
        "outputId": "f70f96c6-9936-4d8f-9075-c5d347738857"
      },
      "source": [
        "#Distinct values for Categorical columns\r\n",
        "#The distinct() will come in handy when you want to determine the unique values in the categorical columns in the dataframe.\r\n",
        "\r\n",
        "df.select(\"PaymentMethod\").distinct().show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|       PaymentMethod|\n",
            "+--------------------+\n",
            "|Credit card (auto...|\n",
            "|        Mailed check|\n",
            "|Bank transfer (au...|\n",
            "|    Electronic check|\n",
            "+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zmVWSmOEqaB"
      },
      "source": [
        "Map reduce example:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qMnKKNQ-mPZ",
        "outputId": "476f7952-9e51-4836-94d3-b49f4934dedd"
      },
      "source": [
        "# For map reduce we need to create SparkContext so that we can read a textfile and perform mapping function on it. \r\n",
        "from pyspark import SparkContext\r\n",
        "sc = SparkContext.getOrCreate()\r\n",
        "text_file = sc.textFile(\"/content/icp4.txt\")\r\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\r\n",
        "             .map(lambda word: (word, 1)) \\\r\n",
        "             .reduceByKey(lambda a, b: a + b)\r\n",
        "for x in counts.collect():\r\n",
        "    print (x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('People', 1)\n",
            "('who', 1)\n",
            "('have', 1)\n",
            "('been', 1)\n",
            "('fully', 1)\n",
            "('vaccinated', 1)\n",
            "('against', 1)\n",
            "('coronavirus', 1)\n",
            "('--', 2)\n",
            "('right', 1)\n",
            "('now', 1)\n",
            "('that', 1)\n",
            "('means', 1)\n",
            "('with', 2)\n",
            "('two', 1)\n",
            "('doses', 1)\n",
            "('of', 1)\n",
            "('either', 1)\n",
            "('the', 4)\n",
            "('Pfizer/BioNTech', 1)\n",
            "('or', 1)\n",
            "('Moderna', 1)\n",
            "('vaccine', 1)\n",
            "('can', 1)\n",
            "('skip', 1)\n",
            "('quarantine', 1)\n",
            "('if', 1)\n",
            "('they', 2)\n",
            "('are', 1)\n",
            "('exposed', 1)\n",
            "('to', 2)\n",
            "('someone', 1)\n",
            "('infected', 1)\n",
            "('virus,', 1)\n",
            "('US', 1)\n",
            "('Centers', 1)\n",
            "('for', 2)\n",
            "('Disease', 1)\n",
            "('Control', 1)\n",
            "('and', 1)\n",
            "('Prevention', 1)\n",
            "('said', 1)\n",
            "('Wednesday.That', 1)\n",
            "(\"doesn't\", 1)\n",
            "('mean', 1)\n",
            "('should', 1)\n",
            "('stop', 1)\n",
            "('taking', 1)\n",
            "('precautions,', 1)\n",
            "('CDC', 1)\n",
            "('noted', 1)\n",
            "('in', 1)\n",
            "('updated', 1)\n",
            "('guidance.', 1)\n",
            "(\"It's\", 1)\n",
            "('just', 1)\n",
            "('not', 1)\n",
            "('necessary', 1)\n",
            "('them', 1)\n",
            "('quarantine.', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}